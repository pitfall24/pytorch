{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH / 'mnist'\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = 'https://github.com/pytorch/tutorials/raw/master/_static/'\n",
    "FILENAME = 'mnist.pkl.gz'\n",
    "\n",
    "if not(PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open('wb').write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pyplot.imshow(x_train[random.randint(0, 50000)].reshape((28, 28)), cmap='gray')\n",
    "print(f'dataset shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, \n",
    "    (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "\n",
    "n, c = x_train.shape\n",
    "\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural net from scratch (no torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5321, -1.8739, -2.5706, -2.1755, -2.0346, -2.1408, -2.6206, -2.1959,\n",
      "        -2.7334, -2.5304], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3855, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    \n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment set_trace() below for debugging\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        \n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        \n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            \n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0830, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0830, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2286, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            \n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            \n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "                \n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0794, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3939, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0813, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    \n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        \n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        \n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0817, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs:i * bs + bs]\n",
    "        \n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0825, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3676)\n",
      "1 tensor(0.3192)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "        \n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fit() and get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func,xb, yb, opt)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, calid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True), \n",
    "        DataLoader(valid_ds, batch_size=bs * 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.559811114032566\n",
      "1 4.206599202680588\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_ds, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1 ,1, 28, 28)\n",
    "        \n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        \n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        \n",
    "        return xb.view(-1, xb.size(1))\n",
    "    \n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.35787331001758577\n",
      "1 0.26930499792099\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.45344949584007266\n",
      "1 0.2846430236339569\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess), \n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.AvgPool2d(4), \n",
    "    Lambda(lambda x: x.view(x.size(0), -1)), \n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "            \n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.AdaptiveAvgPool2d(1), \n",
    "    Lambda(lambda x: x.view(x.size(0), -1)), \n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4215668640613556\n",
      "1 0.29769401445388793\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2612275622844696\n",
      "1 0.2180973711490631\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ecd4b7f8467236ee89e6968b202c0220983dcb008045e70441c4d1a4cdc7f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
